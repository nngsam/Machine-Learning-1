\documentclass{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{vntex}
\usepackage{amsmath,amssymb}
\usepackage{parskip}
\usepackage{graphicx}

% Margins
\usepackage[top=2.5cm, left=3cm, right=3cm, bottom=4.0cm]{geometry}
% Colour table cells
\usepackage[table]{xcolor}

% Get larger line spacing in table
\newcommand{\tablespace}{\\[1.25mm]}
\newcommand\Tstrut{\rule{0pt}{2.6ex}}         % = `top' strut
\newcommand\tstrut{\rule{0pt}{2.0ex}}         % = `top' strut
\newcommand\Bstrut{\rule[-0.9ex]{0pt}{0pt}}   % = `bottom' strut

%%%%%%%%%%%%%%%%%
%     Title     %
%%%%%%%%%%%%%%%%%

\title{Machine Learning 1 - Week 1 }
\author{Nguyễn Thị Kiều Nhung \ 11203041}
\date{17.8.22}
\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%
%   Problem 1   %
%%%%%%%%%%%%%%%%%
\section*{Problem 1}
\subsection*{a.}
\textbf{Marginal distributions of $p(x)$:} \\

$p(x_1) = 0.1 + 0.05 + 0.01 = 0.16 $ \\
$p(x_2) = 0.02 + 0.1 + 0.05 = 0.17 $ \\
$p(x_3) = 0.03 + 0.05 + 0.03 = 0.11 $ \\
$p(x_4) = 0.1 + 0.07 + 0.05 = 0.22 $ \\
$p(x_5) = 0.1 + 0.2 + 0.04 = 0.34 $ \\

\textbf{Marginal distributions of $p(y)$:} \\

$p(y_1) = 0.01 + 0.02 + 0.03 + 0.1 + 0.1 = 0.26 $\\
$p(y_2) = 0.05 + 0.1 + 0.05 + 0.07 + 0.2 = 0.47 $ \\
$p(y_3) = 0.1 + 0.05 + 0.03 + 0.05 + 0.04 = 0.27 $ \\ 

\subsection*{b.}
\textbf{The conditional distributions of $p(x|Y = y_1)$:} \\

$p(x_1|y_1) = \frac{0.01}{0.26} = \frac{1}{26}$\\

$p(x_2|y_1) = \frac{0.02}{0.26} = \frac{1}{13}$ \\

$p(x_3|y_1) = \frac{0.03}{0.26} = \frac{3}{26}$\\

$p(x_4|y_1) = \frac{0.1}{0.26} = \frac{5}{13}$\\

$p(x_5|y_1) = \frac{0.1}{0.26} = \frac{5}{13}$\\

\textbf{The conditional distributions of $p(x|Y = y_3)$:} \\

$p(x_1|y_3) = \frac{0.1}{0.27} = \frac{10}{27}$ \\


$p(x_2|y_3) = \frac{0.05}{0.27} = \frac{5}{27}$ \\

$p(x_3|y_3) = \frac{0.03}{0.27} = \frac{1}{9}$ \\

$p(x_4|y_3) = \frac{0.05}{0.27} = \frac{5}{27}$ \\

$p(x_5|y_3) = \frac{0.04}{0.27} = \frac{4}{27}$ \\


%%%%%%%%%%%%%%%%%
%   Problem 2   %
%%%%%%%%%%%%%%%%%
\section*{Problem 2}
Prove $$
E_X[X] = E_Y\Bigg[E_X[x|y]\Bigg]
$$
$E_X[x|y]$: the expected value of x under the conditional distribution p(x,y) 

We will start with:
\begin{equation}
    \begin{split}
    \textbf{RHS} & = E_Y\Bigg[E_X[x|y]\Bigg] \\
        & = E_Y \Bigg[\sum_x x \times p(X=x|Y=y)\times p(Y=y) \Bigg] \\
        & = \sum_x\sum_y x \times p(X=x|Y=y) \times p(Y=y) \\
        & = \sum_x x \sum_y p(X=x|Y=y)\times p(Y=y) \\
        & = \sum_x p(X=x)  \\
        & = E_X[x] = \textbf{LHS} \\
    \end{split}
\end{equation}

The equation has been proved.
                

%%%%%%%%%%%%%%%%%
%   Problem 3   %
%%%%%%%%%%%%%%%%%

\section*{Problem 3}
Let $A$: "Người được phỏng vấn sử dụng sản phẩm X" \\
Let $B$: "Người được phỏng vấn sử dụng sản phẩm Y" \\

As provided, 
\begin{align*}

        &  \centerline{p($A$) = 0.207} \\
            \centerline{p($B$) = 0.5} \\
            \centerline{p($A|B$) = 0.365} \\
\end{align*}
\subsection*{a.}
\ The probability of that random interviewed person uses both X and Y $is$
$$
p(A,B) = p(B)\times p(A|B) = 0.5\times 0.365 = 0.1825 
$$
\subsection*{b.}
\ The probability of that random interviewed person uses Y, known that doesn't use X $is$
\begin{equation}
    \begin{split}
    p(B|\bar{A}) = \frac{p(\bar{A}|B)\times p(B)}{p(\bar{A})} 
    & = \frac{p(\bar{A}|B)\times 0,5}{1 - p(\bar{A})} 
    \end{split}
\end{equation}

Meanwhile, we have: \\
\begin{equation}
    \begin{split}
    p(\bar{A}|B) & = \frac{p(\bar{A}B)}{p(B)} \\
                 & = \frac{p(B) - p(AB)}{p(B)} \\
                 & = \frac{0.5 - 0.1825}{0.5} \\
                 & = 0.635 
    \end{split}
\end{equation}

Substitute (3) to (2), we get:
\begin{equation}
    \begin{split}
    p(B|\bar{A}) & = \frac{0.635\times 0.5}{1 - 0.207}
                 & = 0.4004
    \end{split}
\end{equation}
\textbf{Result}: \ 
$ p(B|\bar{A}) = 0.4004 $



%%%%%%%%%%%%%%%%%
%   Problem 4   %
%%%%%%%%%%%%%%%%%

\section*{Problem 4}
Prove the relationship:
$$
V_X = E_X[x^2] - (E_X[x])^2
$$

As you know, variance is defined as the expected squared difference between a random variable and the mean a.k.a expected value: \\
$$
Var(X) = E[(X- \mu)^2]
$$

Then,
\begin{equation}
    \begin{split}
    V_X & = E_X[(x-\mu)^2] \\
        & = E_X[(x - E_X[x])^2] \\
        & = E_X[(x - E_X[x])\times(x - E_X[x])] \\
        & = E_X[ x^2 - 2\times x\times E_X[x] + (E_X[x])^2 ] \\
        & = E_X[x^2] - 2\times E_x[x\times E_X[x]] + (E_X[x])^2  \\
        & = E_X[x^2] - 2\times E_X[x]\times E_X[x] + (E_X[x])^2 \\
        & = E_X[x^2] - (E_X[x])^2 
    \end{split}
\end{equation}

We have proved the \textbf{LHS} = \textbf{RHS}

%%%%%%%%%%%%%%%%%
%   Problem 5   %
%%%%%%%%%%%%%%%%%

\section*{Problem 5}

Assumption: \\
- one door has car\\
- the two remaining have goat \\
- these doors are equally likely \\
- the contestant has no idea which one has car but Monty knows which is which \\
- assuming that you, the contestant want the car not the goat \\

\textbf {\textit{First,} don't switch case}  \\

Let S: "$success$" \\ 
\implies $p(S)$ = \frac{1}{3} \\

So whatever door you choose, the probability of getting the car is $\frac{1}{3}$ if you don't switch. \\

\textbf {\textit{Second,} switch case}\\

    Assume you will always switch, then Let $\textbf{S'}$: "success when \textit{switched}" \\
    Let $D_j$: 'Door j has car' (j = {1,2,3}) \\
    
    By sum rule:
    \begin{equation}
        \begin{split}
        p(S') & = p(S'|D_1)\times p(D_1) + p(S'|D_2)\times p(D_2) + p(S'|D_3)\times p(D_3) \\
              & = p(S'|D_1)\times \frac{1}{3} + p(S'|D_2)\times \frac{1}{3} + p(S'|D_3)\times \frac{1}{3} \\
              & = 0 + 1 \times \frac{1}{3} + 1 \times \frac{1}{3} \\
              & = \frac{2}{3}
        \end{split}
    \end{equation}
In first case of $D_j$, \textit{$ p(S'|D_1) = 0$} because, when we initially pick $D_1$, The car is in $D_1$ (conditionally), Monty Hall knows where the car is, he's gonna open $D_2$ or $D_3$ to reveal a goat, \textbf{then we switch}, we're \textbf{failed}.

Next, \textit{$ p(S'|D_2) = 1$} because, when we initially pick $D_1$, The car is in $D_2$ (conditionally), Monty Hall knows where the car is, he's gonna open $D_3$ to reveal a goat, \textbf{then we switch to $D_2$}, we \textbf{succeed}.

Lastly, \textit{$ p(S'|D_3) = 1$} because, when we initially pick $D_1$, The car is in $D_3$ (conditionally), Monty Hall knows where the car is, he's gonna open $D_2$ to reveal a goat, \textbf{then we switch to $D_3$}, we \textbf{succeed}.
    
Comparing of $not switching$ to $switching$, $p(S) < p(S')$ ($\frac{1}{3}$ < $\frac{2}{3}$), the chance of success when we switch is bigger, \textbf{\textit{you should switch if you want to get a car instead of a goat. }}


\end{document}





